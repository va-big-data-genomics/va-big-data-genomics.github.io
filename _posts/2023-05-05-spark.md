---
layout: post
title:  "Spark"
date:   2023-05-05 00:00:00
author: Daniel Cotter
categories: jekyll update
---

# Spark

One of the most popular distributed computing frameworks of the last fifteen years is Spark, an in-memory computation engine developed at Berkeley before being open-sourced and sponsored by the Apache project. The Broad Institute's Hail framework is written on Spark, and Google Cloud Platform provides a managed version of Spark in Dataproc, which we use for genomic computational tasks on the MVP project, so it is useful to have a high-level understanding of Spark and distributed computing. This blog post is a _very_ high-level introduction to both.

## Distributed computing
Many data sets and computations exceed the limits of single computers. Historically, the solution was to make computers more powerful and give them larger storage – this is called _scaling up_ or _scaling vertically_, and the resulting computers are called _supercomputers_. It works, up to a point, but supercomputers are expensive and rare. Another solution is to scale _out_ or _horizontally_; by distributing pieces of the work across a large number of commodity (i.e. run of the mill) computers, the same results can be had with less expense and more resilience. This is called _distributed_ computing, and has seen an explosion in popularity in the last twenty years.

Another way of expressing it, from _Spark: The Definitive Guide_:
> A cluster, or group, of computers, pool the resources of many machines together, giving us the ability to use all the cumulative resources as if they were a single computer.

### A short history
The first distributed computing framework to achieve mass popularity was Hadoop, first released in 2006. With Hadoop, a master node distributes data and computational tasks to worker nodes, which run the computation and write the results to a specialized file system (Hadoop File System, or HDFS).

According to the paper introducing Spark in 2010 – [Spark: Cluster Computing with Working Sets (2010, Zaharia et al)](https://www.usenix.org/legacy/event/hotcloud10/tech/full_papers/Zaharia.pdf) – the prime motivation was to design a system that worked better for algorithms that do not use an _acyclic data flow model_. This is computer science jargon, by the way, for data that only moves in one direction – acyclically – from start to finish. Many machine learning algorithms are _iterative_, or _cyclic_; that is, the results of first pass become the input to the second pass, which become the input to the third pass, and so on, until an acceptable result is reached. The results were impressive: in the paper, the authors claim "Spark can outperform Hadoop by 10x in iterative machine learning jobs, and can be used to interactively query a 39 GB dataset with sub-second response time." And that was version 1 – Spark is on version 3 currently.

Also, although not mentioned in the initial paper, Spark's architecture contrasts markedly with Hadoop and overcomes some of Hadoop's limitations. For one, Hadoop has a much larger scope than Spark: whereas Spark is a computation engine, Hadoop is that, plus a file system and a cluster manager, all tightly integrated. This might sound like a good thing, but it's often preferable to design more modularly than monolithically, with narrowly-purposed systems that can integrate with a variety of other systems. To that point, Hadoop is closely tied to its own file system and cluster manager, whereas Spark can load data from HDFS, Azure Storage, Google Cloud Storage, Amazon S3, Apache Cassandra, etc. and work with several cluster managers, such as its own built-in manager, but also Hadoop YARN or Apache Mesos. For another, Spark does its computations in memory, whereas Hadoop writes all of the intermediate results to disk. Memory being much faster than disk, this gives Spark a big advantage in computational speed. 

### An aside
The _map-reduce_ paradigm is virtually inseparable from modern distributed computing. _Map_ and _reduce_ are terms borrowed from functional programming languages like Lisp, meaning, respectively, to compute a function on each item of a set (_mapping_ from an input set to an output set) and aggregating the results (_reducing_ the output of the mapping function from many values to one). Mapping is done on the worker nodes on partitions of the full data set, while reducing is done on the master node on the results of the mapping. Both Hadoop and Spark use the map-reduce paradigm.


## A recent experience with Hail & Spark

My goal was to run the burden testing algorithm on an early version of the 100k genomes of data release 2. However: I ran into a spate of problems (cluster size limitations in dev, [version incompatibilities between VM images and Hail](https://github.com/va-big-data-genomics/mvp-burden-testing/issues/4), Jupyter kernel not talking to Spark, cloud console hanging when I was on the VPN, etc.) that prevented me from just running the same code that had worked on the 10k genomes before.

Early on, I figured out I would have to run it in production, since development clusters are limited to 1000 nodes, and I thought this might be the problem. Then the cluster I was using crashed when running the burden testing job (specifically, the linear regression step). The error message was vague and did not come up in my searches. The logs did not provide much insight, either. It seems when a compute- or memory-intensive job runs, there are always a small percentage of machines that fail for one reason or another, and this is not an indication of a coding error.

### Creating the cluster from the command line: `hailctl` vs `gcloud`

When I first started working on the burden testing analysis, I was creating the Dataproc cluster from the GCP user console, which is fine, but it doesn't allow for source control or easy sharing of settings, so I knew I would eventually need to move this step to the command line. I had seen Paul and Joe creating clusters using `hailctl`, but since they were ultimately being created on Google Cloud Platform, I wanted to start with `gcloud` and see what was really happening before using a convenience tool. However, I was having so many problems with the resulting cluster, I decided to give `hailctl` a try anyway. I was intially reluctant to do because of the seemingly black-box nature of the command, but I was pleasantly surprised to find it showed the exact gcloud command it was using.

First, the hailctl command:

```
hailctl dataproc start dcotter-std-gp-autoscaling-jupyter \
  --image-version=2.1.7-debian11 \
  --enable-component-gateway \
  --optional-components=JUPYTER \
  \
  --autoscaling-policy=MVP_autoscaling_policy  \
  --master-machine-type=n1-highmem-8 \
  --worker-machine-type=n1-highmem-8 \
  --worker-boot-disk-size=1000 \
  --secondary-worker-type=non-preemptible \
  --preemptible-worker-boot-disk-size=1000 \
  --properties=dataproc:dataproc.logging.stackdriver.enable=true,dataproc:dataproc.monitoring.stackdriver.enable=true,spark:spark.sql.shuffle.partitions=24240,spark:spark.default.parallelism=24240
```

The resulting `gcloud` command:
```
gcloud dataproc clusters create dcotter-std-gp-autoscaling-jupyter \
    --image-version=2.1.2-debian11 \
    --properties=^|||^spark:spark.task.maxFailures=20|||spark:spark.driver.extraJavaOptions=-Xss4M|||spark:spark.executor.extraJavaOptions=-Xss4M|||spark:spark.speculation=true|||hdfs:dfs.replication=1|||dataproc:dataproc.logging.stackdriver.enable=true|||dataproc:dataproc.monitoring.stackdriver.enable=true|||spark:spark.sql.shuffle.partitions=24240|||spark:spark.default.parallelism=24240|||spark:spark.driver.memory=41g|||yarn:yarn.nodemanager.resource.memory-mb=50585|||yarn:yarn.scheduler.maximum-allocation-mb=25292|||spark:spark.executor.cores=4|||spark:spark.executor.memory=10117m|||spark:spark.executor.memoryOverhead=15175m|||spark:spark.memory.storageFraction=0.2|||spark:spark.executorEnv.HAIL_WORKER_OFF_HEAP_MEMORY_PER_CORE_MB=6323 \
    --initialization-actions=gs://hail-common/hailctl/dataproc/0.2.112/init_notebook.py \
    --metadata=^|||^WHEEL=gs://hail-common/hailctl/dataproc/0.2.112/hail-0.2.112-py3-none-any.whl|||PKGS=aiohttp==3.8.4|aiohttp-session==2.12.0|aiosignal==1.3.1|async-timeout==4.0.2|asyncinit==0.2.4|asynctest==0.13.0|attrs==22.2.0|avro==1.11.1|azure-core==1.26.3|azure-identity==1.12.0|azure-storage-blob==12.14.1|bokeh==1.4.0|boto3==1.26.73|botocore==1.29.73|cachetools==5.3.0|certifi==2022.12.7|cffi==1.15.1|charset-normalizer==3.0.1|commonmark==0.9.1|cryptography==39.0.1|decorator==4.4.2|deprecated==1.2.13|dill==0.3.6|frozenlist==1.3.3|google-api-core==2.11.0|google-auth==2.14.1|google-cloud-core==2.3.2|google-cloud-storage==2.7.0|google-crc32c==1.5.0|google-resumable-media==2.4.1|googleapis-common-protos==1.58.0|humanize==1.1.0|hurry-filesize==0.9|idna==3.4|isodate==0.6.1|janus==1.0.0|jinja2==3.0.3|jmespath==1.0.1|markupsafe==2.1.2|msal==1.21.0|msal-extensions==1.0.0|msrest==0.7.1|multidict==6.0.4|nest-asyncio==1.5.6|numpy==1.21.6|oauthlib==3.2.2|orjson==3.8.6|packaging==23.0|pandas==1.3.5|parsimonious==0.8.1|pillow==9.4.0|plotly==5.10.0|portalocker==2.7.0|protobuf==3.20.2|py4j==0.10.9.5|pyasn1==0.4.8|pyasn1-modules==0.2.8|pycparser==2.21|pygments==2.14.0|pyjwt[crypto]==2.6.0|python-dateutil==2.8.2|python-json-logger==2.0.6|pytz==2022.7.1|pyyaml==6.0|requests==2.28.2|requests-oauthlib==1.3.1|rich==12.6.0|rsa==4.9|s3transfer==0.6.0|scipy==1.7.3|six==1.16.0|sortedcontainers==2.4.0|tabulate==0.9.0|tenacity==8.2.1|tornado==6.2|typing-extensions==4.5.0|urllib3==1.26.14|uvloop==0.17.0;sys_platform!="win32"|wrapt==1.14.1|yarl==1.8.2 \
    --master-machine-type=n1-highmem-8 \
    --master-boot-disk-size=100GB \
    --num-master-local-ssds=0 \
    --num-secondary-workers=0 \
    --num-worker-local-ssds=0 \
    --num-workers=2 \
    --secondary-worker-boot-disk-size=1000GB \
    --worker-boot-disk-size=1000GB \
    --worker-machine-type=n1-highmem-8 \
    --initialization-action-timeout=20m \
    --labels=creator=dlcott2_stanford_edu \
    --image-version=2.1.7-debian11 \
    --enable-component-gateway \
    --optional-components=JUPYTER \
    --autoscaling-policy=MVP_autoscaling_policy \
    --secondary-worker-type=non-preemptible
```

This created the cluster all right, but it couldn't initialize Hail in Jupyter Lab, due to a Spark backend error. I was able to run `pyspark` from the command line and even initialize Hail in a Python REPL, but not from Jupyter. Also, I noticed it pre-loads the Python packages needed for running Hail, which is great. If I'd known it did that, I could have saved myself some trouble.

### A failure with a useful clue
After getting Hail running from the command line, but not the Jupyter notebook, I decided to try running the burden testing job from the command line. I copied and pasted the useful code from the notebook into a Python file and submitted it to the cluster as a Spark job. Unfortunately, it failed, but in a silver lining, provided a useful error message:

```
% gcloud dataproc jobs submit pyspark burden-testing-wgs-100k-annotated-230220.py --cluster=dcotter-std-gp-autoscaling-jupyter --region=us-west1
Job [caefcabe45074f398f4e195732308206] submitted.
Waiting for job output...
<wall of text>
hail.utils.java.FatalError: HailException: Hail off-heap memory exceeded maximum threshold: limit 6.17 GiB, allocated 6.18 GiB
Report: 6.2G allocated (6.8M blocks / 6.2G chunks), regions.size = 17, 0 current java objects, thread 282: Executor task launch worker for task 13345.19 in stage 16.0 (TID 124643)
```

Looking back at the `gcloud` command generated by `hailctl`, I noticed the property setting: `spark:spark.executorEnv.HAIL_WORKER_OFF_HEAP_MEMORY_PER_CORE_MB=6323` and had a hunch this was the problem, given the error message in the most recent failure. Searching on the error message, "Hail off-heap memory exceeded maximum threshold," turned up very little, so I [posed the question](https://discuss.hail.is/t/hail-off-heap-memory-exceeded-maximum-threshold-error-on-large-analysis-job/3338) to the Hail discussion forum, really to ask what would the likely consequences be, if any, of dropping this setting and letting Hail use as much off-heap memory as it liked. I didn't get a quick response, so I decided just to try it: I took out the property setting `HAIL_WORKER_OFF_HEAP_MEMORY_PER_CORE_MB=6323`, which caused it to default to `Long.MaxValue` in Scala, or 9,223,372,036,854,775,807 MB.

### Finally, SUCCESS
For me, the results were a huge positive – instead of spinning for days before finally crashing, the job spun about 930 secondary workers and finished in _two hours and seven minutes_.

The output of the job at the command line was as follows:

```
% gcloud dataproc jobs submit pyspark burden-testing-wgs-100k-annotated-230220.py --cluster=dcotter-std-gp-autoscaling --region=us-west1        
Job [4be9e3ec4db74b12b91d5552b7ee5fd1] submitted.
Waiting for job output...
23/04/17 20:23:21 INFO SparkEnv: Registering MapOutputTracker
23/04/17 20:23:21 INFO SparkEnv: Registering BlockManagerMaster
23/04/17 20:23:21 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/04/17 20:23:21 INFO SparkEnv: Registering OutputCommitCoordinator
23/04/17 20:23:22 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at dcotter-std-gp-autoscaling-m.c.gbsc-gcp-project-mvp.internal./10.240.1.66:8032
23/04/17 20:23:23 INFO AHSProxy: Connecting to Application History server at dcotter-std-gp-autoscaling-m.c.gbsc-gcp-project-mvp.internal./10.240.1.66:10200
23/04/17 20:23:24 INFO Configuration: resource-types.xml not found
23/04/17 20:23:24 INFO ResourceUtils: Unable to find 'resource-types.xml'.
23/04/17 20:23:25 INFO YarnClientImpl: Submitted application application_1681761290605_0001
23/04/17 20:23:26 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at dcotter-std-gp-autoscaling-m.c.gbsc-gcp-project-mvp.internal./10.240.1.66:8030
23/04/17 20:23:28 INFO GoogleCloudStorageImpl: Ignoring exception of type GoogleJsonResponseException; verified object already exists with desired state.
23/04/17 20:23:29 INFO Hail: SparkUI: http://dcotter-std-gp-autoscaling-m.c.gbsc-gcp-project-mvp.internal:33425
Running on Apache Spark version 3.3.0
SparkUI available at http://dcotter-std-gp-autoscaling-m.c.gbsc-gcp-project-mvp.internal:33425
Welcome to
     __  __     <>__
    / /_/ /__  __/ /
   / __  / _ `/ / /
  /_/ /_/\_,_/_/_/   version 0.2.112-31ceff2fb5fd
LOGGING: writing to /home/hail/hail-20230417-2023-0.2.112-31ceff2fb5fd.log
+--------------+-------+----------+---------------+-----------+----------------+
| gene_symbol  |     n |    sum_x | y_transpose_x |      beta | standard_error |
+--------------+-------+----------+---------------+-----------+----------------+
| str          | int32 |  float64 |       float64 |   float64 |        float64 |
+--------------+-------+----------+---------------+-----------+----------------+
| "AL161785.1" | 10385 | 7.00e+01 |      4.82e+03 | -1.07e+00 |       3.24e-01 |
| "AC107223.1" | 10385 | 2.10e+02 |      1.48e+04 |  5.90e-01 |       1.91e-01 |
| "JARID2"     | 10385 | 6.20e+01 |      4.39e+03 |  1.04e+00 |       3.43e-01 |
| "KIAA0930"   | 10385 | 4.30e+01 |      3.05e+03 |  1.23e+00 |       4.12e-01 |
| "MYOCOS"     | 10385 | 6.00e+00 |      4.00e+02 | -3.25e+00 |       1.10e+00 |
| "AC064843.1" | 10385 | 2.30e+01 |      1.57e+03 | -1.57e+00 |       5.62e-01 |
| "PPARGC1A"   | 10385 | 1.11e+02 |      7.81e+03 |  7.18e-01 |       2.57e-01 |
| "GXYLT1"     | 10385 | 1.00e+00 |      6.30e+01 | -7.19e+00 |       2.69e+00 |
| "PARM1"      | 10385 | 8.10e+01 |      5.73e+03 |  8.05e-01 |       3.02e-01 |
| "FAM230C"    | 10385 | 4.00e+00 |      2.60e+02 | -3.55e+00 |       1.34e+00 |
+--------------+-------+----------+---------------+-----------+----------------+

+-----------+----------+
|    t_stat |  p_value |
+-----------+----------+
|   float64 |  float64 |
+-----------+----------+
| -3.31e+00 | 9.44e-04 |
|  3.09e+00 | 2.00e-03 |
|  3.04e+00 | 2.34e-03 |
|  2.99e+00 | 2.82e-03 |
| -2.96e+00 | 3.08e-03 |
| -2.80e+00 | 5.15e-03 |
|  2.80e+00 | 5.18e-03 |
| -2.67e+00 | 7.53e-03 |
|  2.67e+00 | 7.71e-03 |
| -2.64e+00 | 8.32e-03 |
+-----------+----------+
showing top 10 rows
```

The genes output by the burden test don't seem to match the [genes at Genebass](https://app.genebass.org/gene/undefined/phenotype/continuous-weightadjheight_custom-both_sexes--custom?resultIndex=gene-manhattan&resultLayout=full), but I'll need some help from Paul and Joe with the interpretation of the results. Oddly, the status of the cluster in the Dataproc UI was `Error due to update`, but I could see the job was still running because the stage numbers at the command line were still incrementing, so I didn't stop the job or delete the cluster.

## Appendix: Spark terminology
_cluster_ - a group of physical machines yoked together consisting of a master node and _n_ worker nodes

_cluster manager_
  - maintains cluster of machines that run the Spark application
  - runs on driver node of cluster
  - can be either Spark's built-in cluster manager, Apache Mesos, or Hadoop YARN
  - note: Dataproc (Google's managed Spark/Hadoop cluster service) uses Hadoop YARN by default

_Spark application_
  - consists of logical processes: a driver process and _n_ executor processes

_driver_
  - sits on a node in the cluster
  - runs the `main()` function
  - maintains info on Spark app
  - responds to user's program or interactive input
  - analyzes, distributes, and schedules work across executors
  - "The driver process is the heart of a Spark Application and maintains all relevant information during the lifetime of an application." (_Definitive Guide_)

_executors_
- carry out the work that the driver assigns them
- report state of the computations back to the driver (success or failure)

_resilient distributed datasets_
  - a read-only collection of objects partitioned across a set of machines that can be rebuilt if a partition is lost
  - underlie DataFrames, and other data structures
  - can be accessed directly but don't have to be

_jobs_
  - describe transformations and actions to be performed on data structures
  - "breaks down" into 1 to n stages

_transformations_
  - do not (immediately) return results
  - describe how to change a data structure
  - are used to build up a logical transformation plan
  - are not executed until triggered by an action ("lazy evaluation")

_actions_
  - _always_ return results
  - trigger the execution of the logical transformation plan
  - types of actions:
    - viewing data in the console
    - collecting data to native objects in the respective language
    - writing data to output

_stages_
  - consist of 1 to n tasks that can be executed together to compute the same operation on multiple machines
  - are initiated for shuffle operations (among other things)

_tasks_
  - consist of combinations of blocks of data ("partitions") and sets of transformations that run on a single executor (i.e. a unit of computation applied to a unit of data)
  - are "pipelined" into a single stage when feeding data directly into each other without the need to move data across nodes (ex: `map` -> `filter` -> `map` pipelined into a single stage)
  - are called "shuffles" when they cross partitions, like joins, which force data to be exchanged between executor processes
  - have indices and contexts for each task

